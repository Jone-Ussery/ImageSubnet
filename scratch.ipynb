{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import torch\n",
    "import typing\n",
    "import pydantic\n",
    "import bittensor as bt\n",
    "\n",
    "# Stable diffusion\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
    "from typing import List, Dict, Union, Tuple, Optional\n",
    "\n",
    "bt.debug()\n",
    "\n",
    "# Lets instantiate the stable diffusion model.\n",
    "model =  StableDiffusionPipeline.from_pretrained( \"prompthero/openjourney-v4\", custom_pipeline=\"lpw_stable_diffusion\", torch_dtype=torch.float16 )\n",
    "\n",
    "class TextToImage( bt.Synapse ):\n",
    "    image: typing.Optional[ bt.Tensor ] = None\n",
    "    text: str = pydantic.Field( ..., allow_mutation = False)\n",
    "    height: int = 512\n",
    "    width: int = 512\n",
    "    num_images_per_prompt: int = 1 \n",
    "    num_inference_steps: int = 50\n",
    "    guidance_scale: float = 7.5 \n",
    "    negative_prompt: str = None\n",
    "    seed: int = -1\n",
    "\n",
    "def text_to_image( synapse: TextToImage ) -> TextToImage:\n",
    "    return synapse\n",
    "\n",
    "axon = bt.axon().attach( text_to_image ).start()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/napoli/anaconda3/envs/311/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/napoli/anaconda3/envs/311/lib/python3.11/site-packages/huggingface_hub/file_download.py:649: FutureWarning: 'cached_download' is the legacy way to download files from the HF hub, please consider upgrading to 'hf_hub_download'\n",
      "  warnings.warn(\n",
      "Downloading (…)rocessor_config.json: 100%|██████████| 520/520 [00:00<00:00, 3.33MB/s]\n",
      "Downloading (…)_encoder/config.json: 100%|██████████| 602/602 [00:00<00:00, 5.29MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Downloading (…)cheduler_config.json: 100%|██████████| 465/465 [00:00<00:00, 4.22MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 472/472 [00:00<00:00, 356kB/s]\n",
      "\n",
      "Downloading (…)_checker/config.json: 100%|██████████| 4.53k/4.53k [00:00<00:00, 21.9MB/s]\n",
      "Fetching 15 files:  20%|██        | 3/15 [00:01<00:03,  3.24it/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 755/755 [00:00<00:00, 3.63MB/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Downloading (…)f0e/unet/config.json: 100%|██████████| 1.24k/1.24k [00:00<00:00, 14.5MB/s]\n",
      "Downloading (…)tokenizer/merges.txt: 100%|██████████| 525k/525k [00:00<00:00, 1.17MB/s]\n",
      "\n",
      "\n",
      "Downloading (…)5f0e/vae/config.json: 100%|██████████| 610/610 [00:00<00:00, 4.12MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Downloading (…)tokenizer/vocab.json: 100%|██████████| 1.06M/1.06M [00:01<00:00, 577kB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# Stable diffusion\n",
    "import torch\n",
    "import transformers\n",
    "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
    "\n",
    "# Lets instantiate the stable diffusion model.\n",
    "model =  StableDiffusionPipeline.from_pretrained( \"prompthero/openjourney-v4\", custom_pipeline=\"lpw_stable_diffusion\", torch_dtype=torch.float16 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
